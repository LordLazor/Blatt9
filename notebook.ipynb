{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Aufgabe 1\n",
    "\n",
    "### Nachteile:\n",
    "* Convolution-Layer sind deutliche komplexer als Fully Connected Layer. Außerdem erfordert ein Convolution deutlich mehr Rechenleistung gegenüber einem Fully Connected Layer. Ein Fully Connected Layer ist auch einfacher zu implementieren.\n",
    "* Convolution Layer werden außerdem hauptsächlich für Bilderkennung verwendet. Bei anderen Daten funktionieren Fully Connected Layer häuig besser.\n",
    "\n",
    "### Vorteile:\n",
    "* Dadurch, dass Convolution Layer lokale Merkmale innerhalb eines Bildes erkennen, sind sie gegenüber einem Fully Connected Layer viel besser bei der Klassifizierung von Bilddaten."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "343b95be0be375ae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Aufgabe 2\n",
    "### a)\n",
    "Damit das Vanishing Gradient nicht auftritt, hat man die letzten Schichten (den bunten Teil) zwsichendurch noch 2 mal eingefügt, sodass das Model auf dem Weg zum Ziel nicht \"vergisst\", was das eigentliche Ziel ist.\n",
    "### b)\n",
    "Kleinere Filter werden verwendet, da sie weniger Rechenaufwand benötigen. Außerdem können durch kleinere Filter Merkmale und komplexe Muster innerhalb der Daten besser erkannt werden."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99df9fa608cafa4c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Aufgabe 3\n",
    "\n",
    "### a)\n",
    "Im Datenvorbereitungsschritt ist das Ziel den Mittelwert der  unnormierten Daten so nah wie möglich an 0 zu bringen. Außerdem soll während dessen die Standardabweichung bei 1 gehalten werden.\n",
    "\n",
    "### b)\n",
    "Ja, die Modelle sind vortrainiert. Es wird zunächst der Classifier mit 10 Epochen trainiert und anschließend das gesamte Netzwerk für weitere 10 Epochen.\n",
    "\n",
    "### c)\n",
    "\n",
    "\n",
    "### d)\n",
    "Das \"Ensembling\" wird genutzt um Vorhersagen mit Hilfe mehrerer Modelle zu tätigen. Diese Modelle werden innerhalb einer ModuleList gespeichert und später gemeinsam innerhalb der forward(x) Methode verwendet.\n",
    " \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f842899991e730e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Aufgabe 4"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "baf0585e3a357954"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import random\n",
    "from operator import itemgetter\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.utils import make_grid\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.image import imread\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device= torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "example = r\"C:\\Users\\user\\Desktop\\Sciebo Cloud\\5\\Deep Learning\\Blatt 9\\flowers\\daisy\"\n",
    "path = r\"C:\\Users\\user\\Desktop\\Sciebo Cloud\\5\\Deep Learning\\Blatt 9\\flowers\"\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T15:05:36.565927500Z",
     "start_time": "2024-01-12T15:05:36.561919500Z"
    }
   },
   "id": "e27e98dd3999add8"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "transformer = {\n",
    "    'original': transform.Compose([\n",
    "                                 transform.Resize((220, 220)),\n",
    "                                 transform.ToTensor(), \n",
    "                                 transform.Normalize((0.4124234616756439, 0.3674212694168091, 0.2578217089176178), \n",
    "                                                     (0.3268945515155792, 0.29282665252685547, 0.29053378105163574))\n",
    "]), \n",
    "   'dataset1': transform.Compose([\n",
    "                           transform.Resize((220, 220)),\n",
    "                           transform.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "                           transform.RandomRotation(5),\n",
    "                           transform.RandomAffine(degrees=11, translate=(0.1,0.1), scale=(0.8,0.8)),\n",
    "                           transform.ToTensor(),\n",
    "                           transform.Normalize((0.4124234616756439, 0.3674212694168091, 0.2578217089176178), \n",
    "                                               (0.3268945515155792, 0.29282665252685547, 0.29053378105163574)),\n",
    "]), \n",
    "   'dataset2': transform.Compose([\n",
    "                                 transform.Resize((220, 220)),\n",
    "                                 transform.RandomHorizontalFlip(),\n",
    "                                 transform.RandomRotation(10),\n",
    "                                 transform.RandomAffine(translate=(0.05,0.05), degrees=0),\n",
    "                                 transform.ToTensor(),\n",
    "                                 transform.RandomErasing(inplace=True, scale=(0.01, 0.23)),\n",
    "                                 transform.Normalize((0.4124234616756439, 0.3674212694168091, 0.2578217089176178), \n",
    "                                                     (0.3268945515155792, 0.29282665252685547, 0.29053378105163574))]),\n",
    "   'dataset3': transform.Compose([\n",
    "                                 transform.Resize((220, 220)),\n",
    "                                 transform.RandomHorizontalFlip(p=0.5),\n",
    "                                 transform.RandomRotation(15),\n",
    "                                 transform.RandomAffine(translate=(0.08,0.1), degrees=15),\n",
    "                                 transform.ToTensor(),\n",
    "                                 transform.Normalize((0.4124234616756439, 0.3674212694168091, 0.2578217089176178), \n",
    "                                                     (0.3268945515155792, 0.29282665252685547, 0.29053378105163574))\n",
    "                                                     \n",
    "])\n",
    "}\n",
    "\n",
    "bs = 50\n",
    "\n",
    "original = ImageFolder(path, transform=transformer['original'])\n",
    "\n",
    "#all_set = train_val + test\n",
    "train_val, test = train_test_split(original, test_size=0.2, shuffle=True, random_state=43)\n",
    "\n",
    "#train_val = train + val + dataset1 + dataset2 + dataset3\n",
    "train_val = ConcatDataset([train_val, \n",
    "                           ImageFolder(path, transform=transformer['dataset1']),\n",
    "                           ImageFolder(path, transform=transformer['dataset2']),\n",
    "                           ImageFolder(path, transform=transformer['dataset3'])]) \n",
    "\n",
    "train, val = train_test_split(train_val, test_size=0.1, shuffle=True, random_state=43)\n",
    "\n",
    "loaders = {\n",
    "    'train': DataLoader(train, batch_size=bs, num_workers=4, pin_memory=True),\n",
    "    'val': DataLoader(val, batch_size=bs, num_workers=4, pin_memory=True),\n",
    "    'test': DataLoader(test, batch_size=bs, num_workers=4, pin_memory=True)\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(train),\n",
    "    'val': len(val), \n",
    "    'test': len(test),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T15:07:14.633712100Z",
     "start_time": "2024-01-12T15:05:38.337904100Z"
    }
   },
   "id": "d4dcab65a78d2807"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|channel:1| train - mean: -0.08583129197359085, std: 0.9729801416397095\n",
      "|channel:1| val - mean: -0.08091458678245544, std: 0.9846334457397461\n",
      "|channel:1| test - mean: 0.11246329545974731, std: 0.8949926495552063\n",
      "|channel:2| train - mean: -0.05790414661169052, std: 0.9796761870384216\n",
      "|channel:2| val - mean: -0.05654305964708328, std: 0.9897287487983704\n",
      "|channel:2| test - mean: 0.16574203968048096, std: 0.8847255110740662\n",
      "|channel:3| train - mean: -0.02546750381588936, std: 0.9755665063858032\n",
      "|channel:3| val - mean: -0.027507711201906204, std: 0.979667067527771\n",
      "|channel:3| test - mean: 0.13841129839420319, std: 0.969063401222229\n"
     ]
    }
   ],
   "source": [
    "channels = 3\n",
    "\n",
    "for channel in range(channels):\n",
    "    for x in ['train', 'val', 'test']:\n",
    "        #number of pixels in the dataset = number of all pixels in one object * number of all objects in the dataset\n",
    "        num_pxl = dataset_sizes[x]*220*220\n",
    "    \n",
    "        #we go through the butches and sum up the pixels of the objects, \n",
    "        #which then divide the sum by the number of all pixels to calculate the average\n",
    "        total_sum = 0\n",
    "        for batch in loaders[x]:\n",
    "            layer = list(map(itemgetter(channel), batch[0]))\n",
    "            layer = torch.stack(layer, dim=0)\n",
    "            total_sum += layer.sum()\n",
    "        mean = total_sum / num_pxl\n",
    "\n",
    "        #we calculate the standard deviation using the formula that I indicated above\n",
    "        sum_sqrt = 0\n",
    "        for batch in loaders[x]: \n",
    "            layer = list(map(itemgetter(channel), batch[0]))\n",
    "            sum_sqrt += ((torch.stack(layer, dim=0) - mean).pow(2)).sum()\n",
    "        std = torch.sqrt(sum_sqrt / num_pxl)\n",
    "        \n",
    "        print(f'|channel:{channel+1}| {x} - mean: {mean}, std: {std}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T15:14:31.607835700Z",
     "start_time": "2024-01-12T15:07:35.116989500Z"
    }
   },
   "id": "9f7ab56de01ed742"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to C:\\Users\\user/.cache\\torch\\hub\\checkpoints\\vgg16_bn-6c64b313.pth\n",
      "100%|██████████| 528M/528M [00:24<00:00, 22.5MB/s] \n"
     ]
    }
   ],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1) \n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds)), preds\n",
    "\n",
    "losses = {'train':[], 'val':[]}\n",
    "accuracies = {'train':[], 'val':[]}\n",
    "lr = []\n",
    "\n",
    "def train(seed, epochs, model):\n",
    "    \n",
    "  print('Creating a model {}...'.format(seed))\n",
    "\n",
    "  model.to(device)  \n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  if seed==2 or seed==3:\n",
    "    optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay = 1e-5)\n",
    "  else:\n",
    "    optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, verbose=True)\n",
    "  #scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, 0.1, epochs=epochs, steps_per_epoch=len(loaders['train']), cycle_momentum=True)\n",
    "  #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 3, gamma=0.1)\n",
    "  since = time.time()\n",
    "  best_model = copy.deepcopy(model.state_dict())\n",
    "  best_acc = 0.0\n",
    "  for epoch in range(epochs):\n",
    "    for phase in ['train', 'val']:\n",
    "      if phase == 'train':\n",
    "        model.train()\n",
    "      else:\n",
    "        model.eval()\n",
    "      \n",
    "      running_loss = 0.0\n",
    "      running_corrects = 0.0\n",
    "\n",
    "      for inputs, labels in loaders[phase]:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(phase=='train'):\n",
    "          outp = model(inputs)\n",
    "          _, pred = torch.max(outp, 1)\n",
    "          loss = criterion(outp, labels)\n",
    "        \n",
    "          if phase == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#             lr.append(scheduler.get_lr())\n",
    "#             scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()*inputs.size(0)\n",
    "        running_corrects += torch.sum(pred == labels.data)\n",
    "\n",
    "      if phase == 'train':\n",
    "          acc = 100. * running_corrects.double() / dataset_sizes[phase]\n",
    "          scheduler.step(acc)\n",
    "\n",
    "      epoch_loss = running_loss / dataset_sizes[phase]\n",
    "      epoch_acc = running_corrects.double()/dataset_sizes[phase]\n",
    "      losses[phase].append(epoch_loss)\n",
    "      accuracies[phase].append(epoch_acc)\n",
    "      if phase == 'train':\n",
    "        print('Epoch: {}/{}'.format(epoch+1, epochs))\n",
    "      print('{} - loss:{}, accuracy{}'.format(phase, epoch_loss, epoch_acc))\n",
    "      lr.append(scheduler._last_lr)\n",
    "        \n",
    "      if phase == 'val':\n",
    "        print('Time: {}m {}s'.format((time.time()- since)//60, (time.time()- since)%60))\n",
    "        print('=='*31)\n",
    "      if phase == 'val' and epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model = copy.deepcopy(model.state_dict())\n",
    "    #scheduler.step() \n",
    "  time_elapsed = time.time() - since\n",
    "  print('CLASSIFIER TRAINING TIME {}m {}s'.format(time_elapsed//60, time_elapsed%60))\n",
    "  print('=='*31)\n",
    "\n",
    "\n",
    "  model.load_state_dict(best_model)\n",
    "\n",
    "  for param in model.parameters():\n",
    "        param.requires_grad=True\n",
    "\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)  \n",
    "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=2, verbose=True)\n",
    "  #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 3, gamma=0.1)\n",
    "  #scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, 0.001, epochs=epochs, steps_per_epoch=len(loaders['train']), cycle_momentum=True)\n",
    "  for epoch in range(epochs):\n",
    "    for phase in ['train', 'val']:\n",
    "      if phase == 'train':\n",
    "        model.train()\n",
    "      else:\n",
    "        model.eval()\n",
    "      \n",
    "      running_loss = 0.0\n",
    "      running_corrects = 0.0\n",
    "\n",
    "      for inputs, labels in loaders[phase]:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(phase=='train'):\n",
    "          outp = model(inputs)\n",
    "          _, pred = torch.max(outp, 1)\n",
    "          loss = criterion(outp, labels)\n",
    "        \n",
    "          if phase == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#             lr.append(scheduler.get_lr())\n",
    "#             scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()*inputs.size(0)\n",
    "        running_corrects += torch.sum(pred == labels.data)\n",
    "\n",
    "      if phase == 'train':\n",
    "        acc = 100. * running_corrects.double() / dataset_sizes[phase]\n",
    "        scheduler.step(acc)\n",
    "\n",
    "      epoch_loss = running_loss / dataset_sizes[phase]\n",
    "      epoch_acc = running_corrects.double()/dataset_sizes[phase]\n",
    "      losses[phase].append(epoch_loss)\n",
    "      accuracies[phase].append(epoch_acc)\n",
    "      if phase == 'train':\n",
    "        print('Epoch: {}/{}'.format(epoch+1, epochs))\n",
    "      print('{} - loss:{}, accuracy{}'.format(phase, epoch_loss, epoch_acc))\n",
    "      lr.append(scheduler._last_lr)\n",
    "    \n",
    "      if phase == 'val':\n",
    "        print('Time: {}m {}s'.format((time.time()- since)//60, (time.time()- since)%60))\n",
    "        print('=='*31)    \n",
    "      if phase == 'val' and epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model = copy.deepcopy(model.state_dict())\n",
    "    #scheduler.step() \n",
    "  time_elapsed = time.time() - since\n",
    "  print('ALL NET TRAINING TIME {}m {}s'.format(time_elapsed//60, time_elapsed%60))\n",
    "  print('=='*31)\n",
    "\n",
    "  model.load_state_dict(best_model)\n",
    "  return model\n",
    "\n",
    "# In der Aufgabenstellung stand VGG 16. Wir sind uns nicht sicher, ob dies ein Typo war daher haben wir einfach VGG 16 verwendet\n",
    "\n",
    "vgg16_bn = torchvision.models.vgg16_bn(pretrained=True)\n",
    "for param in vgg16_bn.parameters():\n",
    "  param.grad_requires = False\n",
    "\n",
    "vgg16_bn.classifier[6] = nn.Linear(4096, len(original.classes), bias=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T15:19:21.119418800Z",
     "start_time": "2024-01-12T15:18:55.083942100Z"
    }
   },
   "id": "13c0ed0094423d2d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a model 0...\n"
     ]
    }
   ],
   "source": [
    "num_models = 1\n",
    "epochs = 10\n",
    "\n",
    "models = [vgg16_bn]\n",
    "\n",
    "for seed in range(num_models):\n",
    "   train(seed=seed, epochs=epochs, model=models[seed])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-12T15:20:05.444878500Z"
    }
   },
   "id": "a1d8b85f6d5b4c67"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
